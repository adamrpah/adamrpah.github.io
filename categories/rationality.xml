<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>NP Complete Heart (rationality)</title><link>http://www.npcompleteheart.com/</link><description></description><atom:link href="http://www.npcompleteheart.com/categories/rationality.xml" type="application/rss+xml" rel="self"></atom:link><language>en</language><lastBuildDate>Sun, 06 Dec 2015 02:08:20 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>How does cooperation evolve?</title><link>http://www.npcompleteheart.com/posts/how-does-cooperation-evolve.html</link><dc:creator>Adam Pah</dc:creator><description>&lt;div class="row"&gt;
&lt;div class="col-md-8"&gt;
I just finished reading Axelrod's &lt;strong&gt;The Complexity of Cooperation&lt;/strong&gt; and I have to say, it's one of the better scientific books that I can remember reading (period). This is surprising (for me), since it's really just a collection of seven of his published papers along with some commentary. However, his papers are so well written and the commentary is brilliant, especially for someone pursuing research as a career, since it not only provides insight into the genesis of the work but also how it was regarded by journals.
&lt;/div&gt;
&lt;div class="col-md-4"&gt;
&lt;img src="http://www.npcompleteheart.com/images/prisoners_dilemma.jpg"&gt;
&lt;/div&gt;

&lt;!-- TEASER_END --&gt;

&lt;div class="col-md-12"&gt;
&lt;p&gt;
This case is especially so for Chapters 4/5/7, which are concerned with his use of Landscape theory to predict alliances between nations and companies and the diffusion of culture. For all of these papers, he discusses the difficulties in publishing these pieces and then their lack of acceptance in the field at the time. For the landscape theories the lack of acceptance was primarily due to the nonexistence of rational agents and decision-making, while in the culture diffusion model it centered on the absence of "politics of any kind", as so succinctly stated by one reviewer.
&lt;/p&gt;


&lt;p&gt;
In a hilarious twist, or maybe it's based solely on my anti-authoritarian leanings, these three papers were far and away my favorites of the entire compilation. The two landscape theory papers were concerned with predicting the formation of alliances, with Chapter 4 being focused on predicting the split of countries in World War II and Chapter 5 consortium alliances in setting Unix standards in the late 1980s. He describes the distaste that game theorists and (probably) economists had for this work since it didn't have a true "game" or rational decision agents, and instead was inspired by research on spin glass models and is, in reality, a method to find the energy landscape of possible group formations. In a somewhat hilarious turn, despite knowing more than a few people who have done research on spin glass models, this is probably the first piece of work that really made me appreciate the value that is in this model (which, honestly, was lacking in me before). 
&lt;/p&gt;

&lt;p&gt;
But the two run away chapters in my mind were 6 and 7. Chapter 6 was focused on the evolution of new political actors that are superstructures of smaller actors (think the formation of a nation from colonies a la the United States) which was investigated with what he called the tribute model. This was a relatively simple model where an actor in the game is selected at random and then is given the opportunity to attack another actor, which it will do so long as any other actor has less wealth than it does (otherwise it would be trounced in a fight). The opposing actor in this confrontation has the choice between fighting or paying tribute, and it simply selects whichever option costs less. Whenever an actor pays a tribute to another actor this builds a bond between the two and this bond comes into play when one of the actors is attacked by an outsider. What happens then is any actor in an alliance with the attacked country has this obligation to defend its ally, which further reinforces the bond between the two initial actors. Through simulation results results Axelrod showed that these simple behaviors were able to cause the formation of essentially new political actors, namely superstructures of actors with typically one dominant actor that was the caretaker of several minor actors. Furthermore, despite the simplicity of this model there is considerable complexity in the dynamics, namely that it there are many, distinctly different scenarios that can play out at random at 10,000 or more steps into the simulation.
&lt;/p&gt;

&lt;p&gt;
Chapter 7 was an, almost unbelievably simple model that focused on cultural diffusion. Each agent in a 2-dimensional grid was initialized with a vector of cultural traits for &lt;i&gt;n&lt;/i&gt; cultural features. The play of this model was very simple, at random an agent within the grid was selected and with some probability, based on homophily with a neighbor, a dissimilar trait is diffused. There were four major results from this model, with two being relatively intuitive and the other two being momentary head-scratchers.
&lt;/p&gt;

&lt;p&gt;
First, there is the concern of geography. A relatively intuitive result is that the number of stable groups in the population decreases as each agent has more neighbors. This is similar to the first question that comes to mind now, which is what about the internet. What it basically says is that as we have the ability to contact more people, it is more likely we will find a similar person to share traits with. This helps the system reach a relatively smaller number of overall groups. The other was with the size of the grid. In this case there are relatively few cultural groups when the grid is small (say a 5x5 grid) and more as the grid grows into moderate sizes (about 20x20), so far so good in terms of making sense. However, after this point the number of stable final groups starts to decrease, now why is that? Based on the simulations we find out that in a very large grid most of the time is actually just spent with two competing dialects (i.e. a majority with a dialect vector of  and a minority with ) fighting each other. However, while this process is like a random walk, there is a twist that there is a boundary, basically change in the size of the populations can only occur at the border were a majority agent and a minority agent meet. This means that it is most likely that the majority will subsume the minority, it is just that it will take a longer time than in a smaller grid. In the larger population grid, this border is larger which means that while it seems like there will be &lt;b&gt;more&lt;/b&gt; cultural regions to (which is true), there ends up being &lt;b&gt;less&lt;/b&gt; distinct cultural regions because of the overlap in beliefs and this establishment of cultural zones. Basically in any case where two agent share one feature there is the chance that they will assimilate.
&lt;/p&gt;

&lt;p&gt;
Second, is the concern of cultural traits and features, which is slightly more straightforward. The greater the number of cultural traits for a given feature, the more cultural regions that can be expected to form. This is fairly simple, as the number of opinions/options on a distinct issue grow, the easier it is to be surrounded by someone who does not share a similar viewpoint on any of the cultural features. This is something that made me immediately think back to high school, with music and the cliques that formed around them. As each musical genre continued to subdivide (I myself was in the skacore clique), the smaller and more numerous the groups became. What is mildly surprising is the result for cultural features, which shows that as the number of features &lt;b&gt;increases&lt;/b&gt; the number of groups &lt;b&gt;decreases&lt;/b&gt;. After a hot minute this makes sense though, the more issues that exits the easier it is to find &lt;b&gt;at least one&lt;/b&gt; that I agree on with a neighbor. After this initial icebreaker of an agreement it's much easier to open the lines of communication, so to speak, and begin transferring ideas and opinions.
&lt;/p&gt;

&lt;p&gt;
However, the main question that I still have of this model is one of cultural drift. Axelrod addressed this (and the reviewers requested) but the simulation results proved too thorny to unpack easily. I haven't had the time to do a literature search yet so this may be an answered question (the book is 17 years old), but it seems to be a fundamental one. This is especially so with my research interest on the diffusion of innovations within a system What is necessary for new "traits" that are introduced to survive, especially after a system has already reach a steady state? Is it necessary for a system to be in a dynamic state for these traits to survive? I think that these are interesting questions that may be out of reach for the model but that's never stopped me from wasting a week of work....
&lt;/p&gt;

&lt;p&gt;
In any case this is wonderful book that only takes about a night and a glass of whiskey to finish, which means that you really can't go wrong.
&lt;/p&gt;
&lt;/div&gt;

&lt;/div&gt;</description><category>book</category><category>rationality</category><category>review</category><category>science</category><guid>http://www.npcompleteheart.com/posts/how-does-cooperation-evolve.html</guid><pubDate>Sun, 25 Jan 2015 14:47:41 GMT</pubDate></item><item><title>A story of human reasoning</title><link>http://www.npcompleteheart.com/posts/a-story-of-human-reasoning.html</link><dc:creator>Adam Pah</dc:creator><description>&lt;div&gt;&lt;h5&gt;(a first part summary of essays contained within Gigerenzer and Selten's [eds.] &lt;i&gt;Bounded Rationality: The Adaptive Toolbox&lt;/i&gt;)&lt;/h5&gt;

&lt;p&gt;
What will I make for dinner? A relatively simple question that plagues me most nights of the week. However, what is a relatively simple task, albeit one that can be arduous for me, unpacks a can of worms in basic research: through what &lt;b&gt;mental process&lt;/b&gt; do I decide what to make?
&lt;/p&gt;

&lt;p&gt;
Admittedly this is a silly question, but other questions used to motivate this issue are roughly as silly. The point is merely to illuminate the difference between decision-making paradigms. Classically, or as far as my knowledge extends to, we would typically think of solving this problem through maximizing our utility, searching for the best possible answer (the global optima). In the context of our dinner problem, the steps to solving our problem would look like:
&lt;/p&gt;&lt;ol&gt;
&lt;li&gt;mentally assemble all of the possible recipes&lt;/li&gt;
&lt;li&gt;determine which recipes had all of the possible recipes&lt;/li&gt;
&lt;li&gt;determine which recipes had all available ingredients&lt;/li&gt;
&lt;li&gt;account for the spoilage dates of all the ingredients&lt;/li&gt;
&lt;li&gt;identify the meal that would provide the maximum utility (one that uses the most ingredients that are about to spoil the soonest while being feasible to make)&lt;/li&gt; 
&lt;/ol&gt;


&lt;!-- TEASER_END --&gt;

&lt;p&gt;
The reality that this decision methodology ignores are the constraints in the real world. When I start to consider what to cook, the entire process has typically started because I'm hungry. This imposes a very real time constraint because if too much time passes I become what is known as "hangry" (both "hungry" and "angry" at the same time). In the process of maximizing my utility I generally ignore this time constraint and instead suffer in the search for the optimal answer. The situation considerably worsens for me if I am a poor cook and have few or no recipes memorized, since this introduces researching online first to identify possible recipes. There is also the additional kink of, how do I assess when I have spent enough time finding recipes so that the optimal recipe would be in the list of recipes I now possess? I could continue to look further and make comparisons, but this could rapidly lead to a situation where I am continually conducting research to determine if my prior research is sufficient. This leads to decision paralysis and the possibility of infinite regress, i.e. where I just keep going further down the rabbit hole of preparing to make my decision without making any progress towards resolving it.
&lt;/p&gt;

&lt;p&gt;
Crap. At this rate I might not start eating dinner until tomorrow or next week!
&lt;/p&gt;

&lt;p&gt;&amp;lt;&amp;gt;
&lt;/p&gt;&lt;p&gt;
This doesn't really seem to reflect my typical reality though. There is a fairly serious time crunch, wherein I must decide before hanger sets in. 
&lt;/p&gt;
&lt;p&gt;
In the early 1950s, Herbert Simon set out an alternative theory of &lt;i&gt;satisficing&lt;/i&gt; (stemming form the concepts of satisfy and suffice). Using this heuristic we actually go about decision-making in a different manner. Within this paradigm I instead set some minimum value of acceptability and instead evaluate each possible dish as I think of it. As I evaluate some dish I calculate its score based on the number of ingredients it uses that are about to spoil. As soon as I think of a dish that has a score greater than my set point I start cooking. I don't worry if I have the most optimal dish, I instead just start cooking. 
&lt;/p&gt;

&lt;p&gt;
This is where the bounds on rationality come from, I use a heuristic to achieve a locally optimal solution since it is more than likely good enough and fulfills normal criteria (like a lack of unlimited time). A fully rational agent (in the economic sense) would seek the optimal choice in the situation. An irrational agent would choose at random. A last class, which some like to equate to bounded rationality but differs, is a ration agent under constraints. We could say that in our dinner problem I am aware of the available time constraint and use that as a factor in my utility. However, in this situation I am still seeking the global maximum utility within the constraints of my problem, which differs from my heuristic of take the first answer that satisfices my concerns.
&lt;/p&gt;

&lt;p&gt;
And at this point I'll conclude my first summary of the works. From here we start exploring the role that the environment plays in decision-making, and our ability to exploit it when it doesn't change rapidly with heuristics, but that seems like a good second topic.
&lt;/p&gt;&lt;/div&gt;</description><category>book</category><category>rationality</category><category>review</category><guid>http://www.npcompleteheart.com/posts/a-story-of-human-reasoning.html</guid><pubDate>Mon, 24 Nov 2014 14:41:27 GMT</pubDate></item></channel></rss>